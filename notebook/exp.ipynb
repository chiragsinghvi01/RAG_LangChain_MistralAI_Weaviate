{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "320768be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import weaviate\n",
    "from weaviate.classes.init import Auth\n",
    "\n",
    "load_dotenv()\n",
    "WEAVIATE_URL = \"https://konvsbviroeqczjr3hsitw.c0.asia-southeast1.gcp.weaviate.cloud\"\n",
    "WEAVIATE_API_KEY = os.getenv(\"WEAVIATE_API_KEY\")\n",
    "\n",
    "client = weaviate.connect_to_weaviate_cloud(\n",
    "    cluster_url=WEAVIATE_URL,\n",
    "    auth_credentials=Auth.api_key(api_key=WEAVIATE_API_KEY),\n",
    ")\n",
    "print(client.is_ready())\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab46e96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f29335a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71f71f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "data = \"C:/Users/csing/VSCode/Projects/RAG_LangChain_MistralAI_Weaviate/data\"\n",
    "documents = []\n",
    "\n",
    "for pdf_file in os.listdir(data):\n",
    "    if pdf_file.endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(data, pdf_file)\n",
    "        loader = PyPDFLoader(pdf_path, extract_images=True)\n",
    "        documents.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7031f243",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(documents[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6548c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=50,\n",
    ")\n",
    "split_docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17d1431f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned metadata for 382 documents\n"
     ]
    }
   ],
   "source": [
    "# Clean document metadata for Weaviate compatibility\n",
    "import re\n",
    "\n",
    "def clean_metadata_keys(metadata):\n",
    "    cleaned = {}\n",
    "    for key, value in metadata.items():\n",
    "        clean_key = re.sub(r'[^A-Za-z0-9_]', '_', key)\n",
    "        if clean_key and not re.match(r'^[A-Za-z_]', clean_key):\n",
    "            clean_key = '_' + clean_key\n",
    "        cleaned[clean_key[:230]] = value\n",
    "    return cleaned\n",
    "\n",
    "# Apply cleaning to all documents\n",
    "for doc in split_docs:\n",
    "    doc.metadata = clean_metadata_keys(doc.metadata)\n",
    "\n",
    "print(f\"Cleaned metadata for {len(split_docs)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "060419fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cb790bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created vector store with 382 documents\n"
     ]
    }
   ],
   "source": [
    "from langchain_weaviate.vectorstores import WeaviateVectorStore\n",
    "vector_db = WeaviateVectorStore.from_documents(\n",
    "    split_docs,\n",
    "    embeddings,\n",
    "    client=client,\n",
    ")\n",
    "\n",
    "print(f\"Successfully created vector store with {len(split_docs)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff19199",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vector_db.similarity_search(\"What is the main topic of the document?\", k=3)\n",
    "\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"Result {i+1}: {doc.page_content}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfa8817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "You are an expert in question answering tasks.\n",
    "Use the following piece of retrieved context to answer the question.\n",
    "If the context does not provide enough information, say \"I don't know\".\n",
    "Use the context to answer the question as accurately as possible.\n",
    "Use ten sentences maximum to answer the question.\n",
    "\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab37998e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFacePipeline\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "print(f\"Loading model {model_name}...\")\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=model_name,\n",
    "    task=\"text-generation\",\n",
    "    model_kwargs={\"temperature\": 0.1, \"max_length\": 512},\n",
    ")\n",
    "\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28b696df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722565e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": vector_db.as_retriever(), \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50d0dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain.invoke({\"question\": \"What is the main topic of the document?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
